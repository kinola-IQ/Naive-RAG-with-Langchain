{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184bafa7",
   "metadata": {},
   "source": [
    "Document loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb904fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader('pdf')\n",
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36558dd4",
   "metadata": {},
   "source": [
    "Splitting docs (this helps to improve retrieval speed in a naive rag workflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbbb1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators = ['\\n\\n','\\n',' ',''],\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "\n",
    "data = splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195394bd",
   "metadata": {},
   "source": [
    "Instantiating a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee18a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chroma import Chroma\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# data storage for retrieval\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small',api_key = os.getenv('openai_api_key'))\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents = data,\n",
    "    embedding = embeddings\n",
    "    persist_path = 'path/directory'\n",
    ")\n",
    "\n",
    "# retriever\n",
    "retriever  = vector_store.as_retriever(\n",
    "    search_type = 'similarity' \\\n",
    "    search_kwargs = {'k':2}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ab62e6",
   "metadata": {},
   "source": [
    "defining prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6075913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplates\n",
    "\n",
    "prompt = ChatPromptTemplates(\n",
    "    \"\"\"\n",
    "you are a customer care representative, answer the questions using the below context:\n",
    "context: {context}\n",
    "question: {question}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdb7757",
   "metadata": {},
   "source": [
    "Instantiating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf0977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fro langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-40-mini',api_key = '...', temperature = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe32ca0",
   "metadata": {},
   "source": [
    "Creating the chain to link the retriever, the prompt template and the llm sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = ({'context':retriever, 'question': RunnablePassthrough}\n",
    "         |prompt\n",
    "         |llm\n",
    "         |StrOutputParser()\n",
    "         )\n",
    "response = chain.invoke({'question':'how do i get a refund'})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
